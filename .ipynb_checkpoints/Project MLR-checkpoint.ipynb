{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Graduate.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(dataset.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking care of missed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding and One Hot Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "as there are no categorical variables there is no need of Label and One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking and removing Outliers if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.72859016, 1.81923762, 1.77886545, ..., 1.77680627, 0.88640526,\n",
       "        1.40610734],\n",
       "       [1.72166195, 0.66714832, 0.03160087, ..., 0.48585943, 0.88640526,\n",
       "        0.27134907],\n",
       "       [1.71473373, 0.0418297 , 0.52536441, ..., 0.95404281, 0.88640526,\n",
       "        0.0123405 ],\n",
       "       ...,\n",
       "       [1.71473373, 1.19888185, 2.10804114, ..., 1.62785086, 0.88640526,\n",
       "        1.47702973],\n",
       "       [1.72166195, 0.39631872, 0.68995225, ..., 0.24236699, 1.12815215,\n",
       "        0.0585819 ],\n",
       "       [1.72859016, 0.93301508, 0.95592621, ..., 0.76721964, 1.12815215,\n",
       "        0.83872821]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "z = np.abs(stats.zscore(dataset))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 3\n",
    "np.where(z>threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperation of Dependent and Independent variables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "as the Serial No column is not used for prediction we simply discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[337.  , 118.  ,   4.  , ...,   4.5 ,   9.65,   1.  ],\n",
       "       [324.  , 107.  ,   4.  , ...,   4.5 ,   8.87,   1.  ],\n",
       "       [316.  , 104.  ,   3.  , ...,   3.5 ,   8.  ,   1.  ],\n",
       "       ...,\n",
       "       [330.  , 120.  ,   5.  , ...,   5.  ,   9.56,   1.  ],\n",
       "       [312.  , 103.  ,   4.  , ...,   5.  ,   8.43,   0.  ],\n",
       "       [327.  , 113.  ,   4.  , ...,   4.5 ,   9.04,   0.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset.iloc[:,1:-1].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92, 0.76, 0.72, 0.8 , 0.65, 0.9 , 0.75, 0.68, 0.5 , 0.45, 0.52,\n",
       "       0.84, 0.78, 0.62, 0.61, 0.54, 0.66, 0.65, 0.63, 0.62, 0.64, 0.7 ,\n",
       "       0.94, 0.95, 0.97, 0.94, 0.76, 0.44, 0.46, 0.54, 0.65, 0.74, 0.91,\n",
       "       0.9 , 0.94, 0.88, 0.64, 0.58, 0.52, 0.48, 0.46, 0.49, 0.53, 0.87,\n",
       "       0.91, 0.88, 0.86, 0.89, 0.82, 0.78, 0.76, 0.56, 0.78, 0.72, 0.7 ,\n",
       "       0.64, 0.64, 0.46, 0.36, 0.42, 0.48, 0.47, 0.54, 0.56, 0.52, 0.55,\n",
       "       0.61, 0.57, 0.68, 0.78, 0.94, 0.96, 0.93, 0.84, 0.74, 0.72, 0.74,\n",
       "       0.64, 0.44, 0.46, 0.5 , 0.96, 0.92, 0.92, 0.94, 0.76, 0.72, 0.66,\n",
       "       0.64, 0.74, 0.64, 0.38, 0.34, 0.44, 0.36, 0.42, 0.48, 0.86, 0.9 ,\n",
       "       0.79, 0.71, 0.64, 0.62, 0.57, 0.74, 0.69, 0.87, 0.91, 0.93, 0.68,\n",
       "       0.61, 0.69, 0.62, 0.72, 0.59, 0.66, 0.56, 0.45, 0.47, 0.71, 0.94,\n",
       "       0.94, 0.57, 0.61, 0.57, 0.64, 0.85, 0.78, 0.84, 0.92, 0.96, 0.77,\n",
       "       0.71, 0.79, 0.89, 0.82, 0.76, 0.71, 0.8 , 0.78, 0.84, 0.9 , 0.92,\n",
       "       0.97, 0.8 , 0.81, 0.75, 0.83, 0.96, 0.79, 0.93, 0.94, 0.86, 0.79,\n",
       "       0.8 , 0.77, 0.7 , 0.65, 0.61, 0.52, 0.57, 0.53, 0.67, 0.68, 0.81,\n",
       "       0.78, 0.65, 0.64, 0.64, 0.65, 0.68, 0.89, 0.86, 0.89, 0.87, 0.85,\n",
       "       0.9 , 0.82, 0.72, 0.73, 0.71, 0.71, 0.68, 0.75, 0.72, 0.89, 0.84,\n",
       "       0.93, 0.93, 0.88, 0.9 , 0.87, 0.86, 0.94, 0.77, 0.78, 0.73, 0.73,\n",
       "       0.7 , 0.72, 0.73, 0.72, 0.97, 0.97, 0.69, 0.57, 0.63, 0.66, 0.64,\n",
       "       0.68, 0.79, 0.82, 0.95, 0.96, 0.94, 0.93, 0.91, 0.85, 0.84, 0.74,\n",
       "       0.76, 0.75, 0.76, 0.71, 0.67, 0.61, 0.63, 0.64, 0.71, 0.82, 0.73,\n",
       "       0.74, 0.69, 0.64, 0.91, 0.88, 0.85, 0.86, 0.7 , 0.59, 0.6 , 0.65,\n",
       "       0.7 , 0.76, 0.63, 0.81, 0.72, 0.71, 0.8 , 0.77, 0.74, 0.7 , 0.71,\n",
       "       0.93, 0.85, 0.79, 0.76, 0.78, 0.77, 0.9 , 0.87, 0.71, 0.7 , 0.7 ,\n",
       "       0.75, 0.71, 0.72, 0.73, 0.83, 0.77, 0.72, 0.54, 0.49, 0.52, 0.58,\n",
       "       0.78, 0.89, 0.7 , 0.66, 0.67, 0.68, 0.8 , 0.81, 0.8 , 0.94, 0.93,\n",
       "       0.92, 0.89, 0.82, 0.79, 0.58, 0.56, 0.56, 0.64, 0.61, 0.68, 0.76,\n",
       "       0.86, 0.9 , 0.71, 0.62, 0.66, 0.65, 0.73, 0.62, 0.74, 0.79, 0.8 ,\n",
       "       0.69, 0.7 , 0.76, 0.84, 0.78, 0.67, 0.66, 0.65, 0.54, 0.58, 0.79,\n",
       "       0.8 , 0.75, 0.73, 0.72, 0.62, 0.67, 0.81, 0.63, 0.69, 0.8 , 0.43,\n",
       "       0.8 , 0.73, 0.75, 0.71, 0.73, 0.83, 0.72, 0.94, 0.81, 0.81, 0.75,\n",
       "       0.79, 0.58, 0.59, 0.47, 0.49, 0.47, 0.42, 0.57, 0.62, 0.74, 0.73,\n",
       "       0.64, 0.63, 0.59, 0.73, 0.79, 0.68, 0.7 , 0.81, 0.85, 0.93, 0.91,\n",
       "       0.69, 0.77, 0.86, 0.74, 0.57, 0.51, 0.67, 0.72, 0.89, 0.95, 0.79,\n",
       "       0.39, 0.38, 0.34, 0.47, 0.56, 0.71, 0.78, 0.73, 0.82, 0.62, 0.96,\n",
       "       0.96, 0.46, 0.53, 0.49, 0.76, 0.64, 0.71, 0.84, 0.77, 0.89, 0.82,\n",
       "       0.84, 0.91, 0.67, 0.95, 0.63, 0.66, 0.78, 0.91, 0.62, 0.52, 0.61,\n",
       "       0.58, 0.57, 0.61, 0.54, 0.56, 0.59, 0.49, 0.72, 0.76, 0.65, 0.52,\n",
       "       0.6 , 0.58, 0.42, 0.77, 0.73, 0.94, 0.91, 0.92, 0.71, 0.71, 0.69,\n",
       "       0.95, 0.74, 0.73, 0.86, 0.71, 0.64, 0.55, 0.58, 0.61, 0.67, 0.66,\n",
       "       0.53, 0.79, 0.92, 0.87, 0.92, 0.91, 0.93, 0.84, 0.8 , 0.79, 0.82,\n",
       "       0.89, 0.93, 0.73, 0.71, 0.59, 0.51, 0.37, 0.69, 0.89, 0.77, 0.68,\n",
       "       0.62, 0.57, 0.45, 0.54, 0.71, 0.78, 0.81, 0.86, 0.87, 0.64, 0.9 ,\n",
       "       0.67, 0.67, 0.59, 0.62, 0.65, 0.71, 0.79, 0.8 , 0.78, 0.83, 0.71,\n",
       "       0.73, 0.7 , 0.68, 0.79, 0.76, 0.65, 0.67, 0.54, 0.53, 0.62, 0.68,\n",
       "       0.87, 0.96, 0.93, 0.73, 0.84])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.81923762,  1.77886545,  0.77558214, ...,  1.09894429,\n",
       "         1.77680627,  0.88640526],\n",
       "       [ 0.66714832, -0.03160087,  0.77558214, ...,  1.09894429,\n",
       "         0.48585943,  0.88640526],\n",
       "       [-0.0418297 , -0.52536441, -0.09979274, ...,  0.01730621,\n",
       "        -0.95404281,  0.88640526],\n",
       "       ...,\n",
       "       [ 1.19888185,  2.10804114,  1.65095702, ...,  1.63976333,\n",
       "         1.62785086,  0.88640526],\n",
       "       [-0.39631872, -0.68995225,  0.77558214, ...,  1.63976333,\n",
       "        -0.24236699, -1.12815215],\n",
       "       [ 0.93301508,  0.95592621,  0.77558214, ...,  1.09894429,\n",
       "         0.76721964, -1.12815215]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc1=StandardScaler()\n",
    "x=sc1.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0418297 ,  0.29757483,  0.77558214, ...,  0.01730621,\n",
       "         0.30380282,  0.88640526],\n",
       "       [ 0.57852607,  0.13298698, -0.09979274, ..., -0.52351283,\n",
       "         0.03899321, -1.12815215],\n",
       "       [-0.48494097, -0.52536441, -0.09979274, ...,  0.01730621,\n",
       "        -0.73888501,  0.88640526],\n",
       "       ...,\n",
       "       [-1.81427477, -2.00665503, -0.97516761, ..., -1.60515091,\n",
       "        -1.71537044,  0.88640526],\n",
       "       [ 0.75577058,  1.12051406, -0.09979274, ..., -0.52351283,\n",
       "         0.76721964,  0.88640526],\n",
       "       [-0.66218548, -1.34830364, -0.09979274, ...,  0.55812525,\n",
       "        -0.02720919, -1.12815215]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.08510438,  2.10804114,  0.77558214, ...,  0.55812525,\n",
       "         2.22367248,  0.88640526],\n",
       "       [ 1.11025959,  0.95592621,  0.77558214, ...,  0.01730621,\n",
       "         1.29683885,  0.88640526],\n",
       "       [ 0.04679255,  0.46216267, -0.09979274, ...,  1.09894429,\n",
       "         0.88307384,  0.88640526],\n",
       "       ...,\n",
       "       [-1.99151928, -2.00665503, -1.85054249, ..., -2.14596996,\n",
       "        -1.54986443, -1.12815215],\n",
       "       [-2.34600829, -0.52536441,  0.77558214, ..., -1.06433187,\n",
       "        -1.84777524, -1.12815215],\n",
       "       [ 0.22403706, -0.36077656, -0.09979274, ...,  0.01730621,\n",
       "         0.15484742,  0.88640526]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mr = LinearRegression()\n",
    "mr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98392749, 0.87052968, 0.81860552, 0.94840838, 0.72670215,\n",
       "       0.9554992 , 0.74211252, 0.65274412, 0.55625703, 0.60115961,\n",
       "       0.64709074, 0.57629002, 0.62322382, 0.6229508 , 0.68600239,\n",
       "       0.5860235 , 0.63288626, 0.64752273, 0.69488846, 0.64534051,\n",
       "       0.8144511 , 0.83897377, 0.72650796, 0.71148135, 0.70033575,\n",
       "       0.48112866, 0.79214178, 0.91820817, 0.91197074, 0.77027343,\n",
       "       0.79740063, 0.90512368, 0.86191734, 0.95271799, 0.53326493,\n",
       "       0.7576453 , 0.88344437, 0.62444231, 0.83676221, 0.6237162 ,\n",
       "       0.64520817, 0.50413256, 0.71029728, 0.75384828, 0.64049137,\n",
       "       0.76399072, 0.89623032, 0.92817675, 0.85554394, 0.54185587,\n",
       "       0.90156524, 0.67303736, 0.61359633, 0.64881646, 0.64032152,\n",
       "       0.89019777, 0.92462569, 1.00023108, 0.97803788, 0.8492642 ,\n",
       "       0.64992632, 0.60741888, 0.9633041 , 0.79059769, 0.57367115,\n",
       "       0.81991934, 0.62178421, 0.61728235, 0.96787082, 0.9086362 ,\n",
       "       0.90988281, 0.80803305, 0.65078956, 0.65564193, 0.85752212,\n",
       "       0.62341768, 0.81056079, 0.63980754, 0.77151939, 0.82964607,\n",
       "       0.6289112 , 0.85630508, 0.66900242, 0.65830486, 0.67801549,\n",
       "       0.74866754, 0.6309396 , 0.86447632, 0.85920902, 0.93533489,\n",
       "       0.96647175, 0.76168484, 0.93555819, 0.7054857 , 0.786786  ,\n",
       "       0.85791106, 0.86755645, 0.51563236, 0.83148842, 0.51779292,\n",
       "       0.82573605, 0.63355542, 0.70878935, 0.60905726, 0.70174535,\n",
       "       0.68071056, 0.70955532, 0.49419059, 0.57080528, 0.61500732,\n",
       "       0.77451714, 0.627891  , 0.8152069 , 0.66306847, 0.74225755,\n",
       "       0.93740571, 0.90638843, 0.78376593, 0.74106841, 0.61866917,\n",
       "       0.85123409, 0.88322445, 0.68264177, 0.85967453, 0.77333035,\n",
       "       0.80006495, 0.65482697, 0.85970525, 0.73740332, 0.94384698,\n",
       "       0.94992884, 0.65890618, 0.73497004, 0.71909809, 0.50771967,\n",
       "       0.87994066, 0.8033973 , 0.76360918, 0.61431547, 0.7894427 ,\n",
       "       0.53781936, 0.78152003, 0.98735674, 0.5493216 , 0.59977212,\n",
       "       0.83034146, 0.66429286, 0.47254656, 0.51665432, 0.74221591])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mr.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97, 0.89, 0.8 , 0.96, 0.72, 0.94, 0.72, 0.46, 0.61, 0.63, 0.62,\n",
       "       0.44, 0.64, 0.65, 0.69, 0.55, 0.65, 0.64, 0.65, 0.54, 0.82, 0.84,\n",
       "       0.78, 0.76, 0.71, 0.47, 0.76, 0.94, 0.91, 0.82, 0.8 , 0.93, 0.89,\n",
       "       0.94, 0.69, 0.78, 0.92, 0.64, 0.84, 0.42, 0.6 , 0.51, 0.73, 0.75,\n",
       "       0.68, 0.77, 0.9 , 0.91, 0.85, 0.54, 0.86, 0.76, 0.61, 0.67, 0.71,\n",
       "       0.92, 0.92, 0.97, 0.96, 0.86, 0.71, 0.53, 0.96, 0.85, 0.42, 0.79,\n",
       "       0.56, 0.62, 0.96, 0.92, 0.93, 0.82, 0.68, 0.64, 0.88, 0.64, 0.84,\n",
       "       0.64, 0.82, 0.86, 0.67, 0.89, 0.74, 0.65, 0.72, 0.76, 0.73, 0.89,\n",
       "       0.87, 0.94, 0.95, 0.79, 0.89, 0.65, 0.78, 0.88, 0.91, 0.56, 0.81,\n",
       "       0.54, 0.83, 0.69, 0.72, 0.71, 0.56, 0.63, 0.66, 0.54, 0.57, 0.71,\n",
       "       0.69, 0.66, 0.79, 0.57, 0.75, 0.94, 0.91, 0.77, 0.73, 0.64, 0.92,\n",
       "       0.9 , 0.71, 0.88, 0.82, 0.8 , 0.66, 0.78, 0.71, 0.92, 0.92, 0.66,\n",
       "       0.76, 0.74, 0.49, 0.91, 0.81, 0.78, 0.59, 0.79, 0.36, 0.78, 0.96,\n",
       "       0.5 , 0.62, 0.85, 0.7 , 0.49, 0.45, 0.73])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8741849196018767"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05088735235483726"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "rmse = sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=a0+a1x1+a2x2+...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.81923762,  1.77886545, ...,  1.09894429,\n",
       "         1.77680627,  0.88640526],\n",
       "       [ 1.        ,  0.66714832, -0.03160087, ...,  1.09894429,\n",
       "         0.48585943,  0.88640526],\n",
       "       [ 1.        , -0.0418297 , -0.52536441, ...,  0.01730621,\n",
       "        -0.95404281,  0.88640526],\n",
       "       ...,\n",
       "       [ 1.        ,  1.19888185,  2.10804114, ...,  1.63976333,\n",
       "         1.62785086,  0.88640526],\n",
       "       [ 1.        , -0.39631872, -0.68995225, ...,  1.63976333,\n",
       "        -0.24236699, -1.12815215],\n",
       "       [ 1.        ,  0.93301508,  0.95592621, ...,  1.09894429,\n",
       "         0.76721964, -1.12815215]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= np.append(arr= np.ones((500,1)).astype(int),values=x,axis=1)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.81923762,  1.77886545, ...,  1.09894429,\n",
       "         1.77680627,  0.88640526],\n",
       "       [ 1.        ,  0.66714832, -0.03160087, ...,  1.09894429,\n",
       "         0.48585943,  0.88640526],\n",
       "       [ 1.        , -0.0418297 , -0.52536441, ...,  0.01730621,\n",
       "        -0.95404281,  0.88640526],\n",
       "       ...,\n",
       "       [ 1.        ,  1.19888185,  2.10804114, ...,  1.63976333,\n",
       "         1.62785086,  0.88640526],\n",
       "       [ 1.        , -0.39631872, -0.68995225, ...,  1.63976333,\n",
       "        -0.24236699, -1.12815215],\n",
       "       [ 1.        ,  0.93301508,  0.95592621, ...,  1.09894429,\n",
       "         0.76721964, -1.12815215]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=np.array(x[:,[0,1,2,3,4,5,6,7]],dtype=float)\n",
    "x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.822</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.819</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   324.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 01 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>8.21e-180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:34</td>     <th>  Log-Likelihood:    </th> <td>  701.38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>  -1387.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>  -1353.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7217</td> <td>    0.003</td> <td>  269.039</td> <td> 0.000</td> <td>    0.716</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0210</td> <td>    0.006</td> <td>    3.700</td> <td> 0.000</td> <td>    0.010</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0169</td> <td>    0.005</td> <td>    3.184</td> <td> 0.002</td> <td>    0.006</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0068</td> <td>    0.004</td> <td>    1.563</td> <td> 0.119</td> <td>   -0.002</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0016</td> <td>    0.005</td> <td>    0.348</td> <td> 0.728</td> <td>   -0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0156</td> <td>    0.004</td> <td>    4.074</td> <td> 0.000</td> <td>    0.008</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0715</td> <td>    0.006</td> <td>   12.198</td> <td> 0.000</td> <td>    0.060</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0121</td> <td>    0.003</td> <td>    3.680</td> <td> 0.000</td> <td>    0.006</td> <td>    0.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>112.770</td> <th>  Durbin-Watson:     </th> <td>   0.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 262.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.160</td>  <th>  Prob(JB):          </th> <td>1.22e-57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.684</td>  <th>  Cond. No.          </th> <td>    5.65</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.822\n",
       "Model:                            OLS   Adj. R-squared:                  0.819\n",
       "Method:                 Least Squares   F-statistic:                     324.4\n",
       "Date:                Tue, 01 Sep 2020   Prob (F-statistic):          8.21e-180\n",
       "Time:                        23:28:34   Log-Likelihood:                 701.38\n",
       "No. Observations:                 500   AIC:                            -1387.\n",
       "Df Residuals:                     492   BIC:                            -1353.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7217      0.003    269.039      0.000       0.716       0.727\n",
       "x1             0.0210      0.006      3.700      0.000       0.010       0.032\n",
       "x2             0.0169      0.005      3.184      0.002       0.006       0.027\n",
       "x3             0.0068      0.004      1.563      0.119      -0.002       0.015\n",
       "x4             0.0016      0.005      0.348      0.728      -0.007       0.010\n",
       "x5             0.0156      0.004      4.074      0.000       0.008       0.023\n",
       "x6             0.0715      0.006     12.198      0.000       0.060       0.083\n",
       "x7             0.0121      0.003      3.680      0.000       0.006       0.019\n",
       "==============================================================================\n",
       "Omnibus:                      112.770   Durbin-Watson:                   0.796\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              262.104\n",
       "Skew:                          -1.160   Prob(JB):                     1.22e-57\n",
       "Kurtosis:                       5.684   Cond. No.                         5.65\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.822</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.820</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   379.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 01 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>4.29e-181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:34</td>     <th>  Log-Likelihood:    </th> <td>  701.32</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>  -1389.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   493</td>      <th>  BIC:               </th> <td>  -1359.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7217</td> <td>    0.003</td> <td>  269.279</td> <td> 0.000</td> <td>    0.716</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0209</td> <td>    0.006</td> <td>    3.694</td> <td> 0.000</td> <td>    0.010</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0171</td> <td>    0.005</td> <td>    3.236</td> <td> 0.001</td> <td>    0.007</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0073</td> <td>    0.004</td> <td>    1.820</td> <td> 0.069</td> <td>   -0.001</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0160</td> <td>    0.004</td> <td>    4.380</td> <td> 0.000</td> <td>    0.009</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0719</td> <td>    0.006</td> <td>   12.481</td> <td> 0.000</td> <td>    0.061</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.0121</td> <td>    0.003</td> <td>    3.691</td> <td> 0.000</td> <td>    0.006</td> <td>    0.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>111.782</td> <th>  Durbin-Watson:     </th> <td>   0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 258.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.152</td>  <th>  Prob(JB):          </th> <td>6.82e-57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.667</td>  <th>  Cond. No.          </th> <td>    5.21</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.822\n",
       "Model:                            OLS   Adj. R-squared:                  0.820\n",
       "Method:                 Least Squares   F-statistic:                     379.1\n",
       "Date:                Tue, 01 Sep 2020   Prob (F-statistic):          4.29e-181\n",
       "Time:                        23:28:34   Log-Likelihood:                 701.32\n",
       "No. Observations:                 500   AIC:                            -1389.\n",
       "Df Residuals:                     493   BIC:                            -1359.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7217      0.003    269.279      0.000       0.716       0.727\n",
       "x1             0.0209      0.006      3.694      0.000       0.010       0.032\n",
       "x2             0.0171      0.005      3.236      0.001       0.007       0.027\n",
       "x3             0.0073      0.004      1.820      0.069      -0.001       0.015\n",
       "x4             0.0160      0.004      4.380      0.000       0.009       0.023\n",
       "x5             0.0719      0.006     12.481      0.000       0.061       0.083\n",
       "x6             0.0121      0.003      3.691      0.000       0.006       0.019\n",
       "==============================================================================\n",
       "Omnibus:                      111.782   Durbin-Watson:                   0.800\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              258.656\n",
       "Skew:                          -1.152   Prob(JB):                     6.82e-57\n",
       "Kurtosis:                       5.667   Cond. No.                         5.21\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=np.array(x[:,[0,1,2,3,5,6,7]],dtype=float)\n",
    "x_opt\n",
    "regression_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.821</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.819</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   452.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 01 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>9.97e-182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:28:34</td>     <th>  Log-Likelihood:    </th> <td>  699.65</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>  -1387.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   494</td>      <th>  BIC:               </th> <td>  -1362.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.7217</td> <td>    0.003</td> <td>  268.651</td> <td> 0.000</td> <td>    0.716</td> <td>    0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0213</td> <td>    0.006</td> <td>    3.760</td> <td> 0.000</td> <td>    0.010</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0183</td> <td>    0.005</td> <td>    3.501</td> <td> 0.001</td> <td>    0.008</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0179</td> <td>    0.004</td> <td>    5.092</td> <td> 0.000</td> <td>    0.011</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0743</td> <td>    0.006</td> <td>   13.221</td> <td> 0.000</td> <td>    0.063</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0125</td> <td>    0.003</td> <td>    3.814</td> <td> 0.000</td> <td>    0.006</td> <td>    0.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>109.027</td> <th>  Durbin-Watson:     </th> <td>   0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 248.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.130</td>  <th>  Prob(JB):          </th> <td>9.07e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.615</td>  <th>  Cond. No.          </th> <td>    4.77</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.821\n",
       "Model:                            OLS   Adj. R-squared:                  0.819\n",
       "Method:                 Least Squares   F-statistic:                     452.1\n",
       "Date:                Tue, 01 Sep 2020   Prob (F-statistic):          9.97e-182\n",
       "Time:                        23:28:34   Log-Likelihood:                 699.65\n",
       "No. Observations:                 500   AIC:                            -1387.\n",
       "Df Residuals:                     494   BIC:                            -1362.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.7217      0.003    268.651      0.000       0.716       0.727\n",
       "x1             0.0213      0.006      3.760      0.000       0.010       0.032\n",
       "x2             0.0183      0.005      3.501      0.001       0.008       0.029\n",
       "x3             0.0179      0.004      5.092      0.000       0.011       0.025\n",
       "x4             0.0743      0.006     13.221      0.000       0.063       0.085\n",
       "x5             0.0125      0.003      3.814      0.000       0.006       0.019\n",
       "==============================================================================\n",
       "Omnibus:                      109.027   Durbin-Watson:                   0.800\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              248.874\n",
       "Skew:                          -1.130   Prob(JB):                     9.07e-55\n",
       "Kurtosis:                       5.615   Cond. No.                         4.77\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=np.array(x[:,[0,1,2,5,6,7]],dtype=float)\n",
    "x_opt\n",
    "regression_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping of Columns which aren't necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('University Rating',axis=1,inplace=True)\n",
    "dataset.drop('SOP',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning and Testing the model with new Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[337.  , 118.  ,   4.5 ,   9.65,   1.  ],\n",
       "       [324.  , 107.  ,   4.5 ,   8.87,   1.  ],\n",
       "       [316.  , 104.  ,   3.5 ,   8.  ,   1.  ],\n",
       "       ...,\n",
       "       [330.  , 120.  ,   5.  ,   9.56,   1.  ],\n",
       "       [312.  , 103.  ,   5.  ,   8.43,   0.  ],\n",
       "       [327.  , 113.  ,   4.5 ,   9.04,   0.  ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset.iloc[:,1:-1].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92, 0.76, 0.72, 0.8 , 0.65, 0.9 , 0.75, 0.68, 0.5 , 0.45, 0.52,\n",
       "       0.84, 0.78, 0.62, 0.61, 0.54, 0.66, 0.65, 0.63, 0.62, 0.64, 0.7 ,\n",
       "       0.94, 0.95, 0.97, 0.94, 0.76, 0.44, 0.46, 0.54, 0.65, 0.74, 0.91,\n",
       "       0.9 , 0.94, 0.88, 0.64, 0.58, 0.52, 0.48, 0.46, 0.49, 0.53, 0.87,\n",
       "       0.91, 0.88, 0.86, 0.89, 0.82, 0.78, 0.76, 0.56, 0.78, 0.72, 0.7 ,\n",
       "       0.64, 0.64, 0.46, 0.36, 0.42, 0.48, 0.47, 0.54, 0.56, 0.52, 0.55,\n",
       "       0.61, 0.57, 0.68, 0.78, 0.94, 0.96, 0.93, 0.84, 0.74, 0.72, 0.74,\n",
       "       0.64, 0.44, 0.46, 0.5 , 0.96, 0.92, 0.92, 0.94, 0.76, 0.72, 0.66,\n",
       "       0.64, 0.74, 0.64, 0.38, 0.34, 0.44, 0.36, 0.42, 0.48, 0.86, 0.9 ,\n",
       "       0.79, 0.71, 0.64, 0.62, 0.57, 0.74, 0.69, 0.87, 0.91, 0.93, 0.68,\n",
       "       0.61, 0.69, 0.62, 0.72, 0.59, 0.66, 0.56, 0.45, 0.47, 0.71, 0.94,\n",
       "       0.94, 0.57, 0.61, 0.57, 0.64, 0.85, 0.78, 0.84, 0.92, 0.96, 0.77,\n",
       "       0.71, 0.79, 0.89, 0.82, 0.76, 0.71, 0.8 , 0.78, 0.84, 0.9 , 0.92,\n",
       "       0.97, 0.8 , 0.81, 0.75, 0.83, 0.96, 0.79, 0.93, 0.94, 0.86, 0.79,\n",
       "       0.8 , 0.77, 0.7 , 0.65, 0.61, 0.52, 0.57, 0.53, 0.67, 0.68, 0.81,\n",
       "       0.78, 0.65, 0.64, 0.64, 0.65, 0.68, 0.89, 0.86, 0.89, 0.87, 0.85,\n",
       "       0.9 , 0.82, 0.72, 0.73, 0.71, 0.71, 0.68, 0.75, 0.72, 0.89, 0.84,\n",
       "       0.93, 0.93, 0.88, 0.9 , 0.87, 0.86, 0.94, 0.77, 0.78, 0.73, 0.73,\n",
       "       0.7 , 0.72, 0.73, 0.72, 0.97, 0.97, 0.69, 0.57, 0.63, 0.66, 0.64,\n",
       "       0.68, 0.79, 0.82, 0.95, 0.96, 0.94, 0.93, 0.91, 0.85, 0.84, 0.74,\n",
       "       0.76, 0.75, 0.76, 0.71, 0.67, 0.61, 0.63, 0.64, 0.71, 0.82, 0.73,\n",
       "       0.74, 0.69, 0.64, 0.91, 0.88, 0.85, 0.86, 0.7 , 0.59, 0.6 , 0.65,\n",
       "       0.7 , 0.76, 0.63, 0.81, 0.72, 0.71, 0.8 , 0.77, 0.74, 0.7 , 0.71,\n",
       "       0.93, 0.85, 0.79, 0.76, 0.78, 0.77, 0.9 , 0.87, 0.71, 0.7 , 0.7 ,\n",
       "       0.75, 0.71, 0.72, 0.73, 0.83, 0.77, 0.72, 0.54, 0.49, 0.52, 0.58,\n",
       "       0.78, 0.89, 0.7 , 0.66, 0.67, 0.68, 0.8 , 0.81, 0.8 , 0.94, 0.93,\n",
       "       0.92, 0.89, 0.82, 0.79, 0.58, 0.56, 0.56, 0.64, 0.61, 0.68, 0.76,\n",
       "       0.86, 0.9 , 0.71, 0.62, 0.66, 0.65, 0.73, 0.62, 0.74, 0.79, 0.8 ,\n",
       "       0.69, 0.7 , 0.76, 0.84, 0.78, 0.67, 0.66, 0.65, 0.54, 0.58, 0.79,\n",
       "       0.8 , 0.75, 0.73, 0.72, 0.62, 0.67, 0.81, 0.63, 0.69, 0.8 , 0.43,\n",
       "       0.8 , 0.73, 0.75, 0.71, 0.73, 0.83, 0.72, 0.94, 0.81, 0.81, 0.75,\n",
       "       0.79, 0.58, 0.59, 0.47, 0.49, 0.47, 0.42, 0.57, 0.62, 0.74, 0.73,\n",
       "       0.64, 0.63, 0.59, 0.73, 0.79, 0.68, 0.7 , 0.81, 0.85, 0.93, 0.91,\n",
       "       0.69, 0.77, 0.86, 0.74, 0.57, 0.51, 0.67, 0.72, 0.89, 0.95, 0.79,\n",
       "       0.39, 0.38, 0.34, 0.47, 0.56, 0.71, 0.78, 0.73, 0.82, 0.62, 0.96,\n",
       "       0.96, 0.46, 0.53, 0.49, 0.76, 0.64, 0.71, 0.84, 0.77, 0.89, 0.82,\n",
       "       0.84, 0.91, 0.67, 0.95, 0.63, 0.66, 0.78, 0.91, 0.62, 0.52, 0.61,\n",
       "       0.58, 0.57, 0.61, 0.54, 0.56, 0.59, 0.49, 0.72, 0.76, 0.65, 0.52,\n",
       "       0.6 , 0.58, 0.42, 0.77, 0.73, 0.94, 0.91, 0.92, 0.71, 0.71, 0.69,\n",
       "       0.95, 0.74, 0.73, 0.86, 0.71, 0.64, 0.55, 0.58, 0.61, 0.67, 0.66,\n",
       "       0.53, 0.79, 0.92, 0.87, 0.92, 0.91, 0.93, 0.84, 0.8 , 0.79, 0.82,\n",
       "       0.89, 0.93, 0.73, 0.71, 0.59, 0.51, 0.37, 0.69, 0.89, 0.77, 0.68,\n",
       "       0.62, 0.57, 0.45, 0.54, 0.71, 0.78, 0.81, 0.86, 0.87, 0.64, 0.9 ,\n",
       "       0.67, 0.67, 0.59, 0.62, 0.65, 0.71, 0.79, 0.8 , 0.78, 0.83, 0.71,\n",
       "       0.73, 0.7 , 0.68, 0.79, 0.76, 0.65, 0.67, 0.54, 0.53, 0.62, 0.68,\n",
       "       0.87, 0.96, 0.93, 0.73, 0.84])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.81923762,  1.77886545,  1.09894429,  1.77680627,  0.88640526],\n",
       "       [ 0.66714832, -0.03160087,  1.09894429,  0.48585943,  0.88640526],\n",
       "       [-0.0418297 , -0.52536441,  0.01730621, -0.95404281,  0.88640526],\n",
       "       ...,\n",
       "       [ 1.19888185,  2.10804114,  1.63976333,  1.62785086,  0.88640526],\n",
       "       [-0.39631872, -0.68995225,  1.63976333, -0.24236699, -1.12815215],\n",
       "       [ 0.93301508,  0.95592621,  1.09894429,  0.76721964, -1.12815215]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['projtransform']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(sc,'projtransform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proj.save']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlr,'proj.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98984856, 0.869772  , 0.82582433, 0.95065124, 0.73122043,\n",
       "       0.95361597, 0.73586402, 0.65143446, 0.55640792, 0.60674939,\n",
       "       0.65074712, 0.57859058, 0.63814211, 0.61049495, 0.68613356,\n",
       "       0.58980676, 0.63533688, 0.65769643, 0.69842372, 0.64342798,\n",
       "       0.80954062, 0.83881624, 0.71628496, 0.70661719, 0.68271276,\n",
       "       0.4843696 , 0.78928878, 0.92263099, 0.90705522, 0.7703689 ,\n",
       "       0.80207112, 0.90088519, 0.86181023, 0.94934272, 0.53235898,\n",
       "       0.77910254, 0.87541477, 0.62597646, 0.83580524, 0.62480037,\n",
       "       0.6514367 , 0.50902627, 0.70707611, 0.76315539, 0.63310612,\n",
       "       0.75992114, 0.90127406, 0.92793573, 0.85519895, 0.53814006,\n",
       "       0.89435318, 0.67807865, 0.62348736, 0.64534802, 0.63973834,\n",
       "       0.88197591, 0.92184386, 0.99803996, 0.97682065, 0.84972868,\n",
       "       0.65051232, 0.59276347, 0.95772378, 0.78850268, 0.55323846,\n",
       "       0.8190907 , 0.62194465, 0.61304289, 0.96595119, 0.91210853,\n",
       "       0.91080311, 0.81247234, 0.64963807, 0.66614288, 0.8514172 ,\n",
       "       0.61833599, 0.80433807, 0.63431822, 0.77522635, 0.83892549,\n",
       "       0.63807903, 0.85703274, 0.66873219, 0.65865934, 0.68149945,\n",
       "       0.7489445 , 0.63498764, 0.86606133, 0.86057599, 0.94104422,\n",
       "       0.97448838, 0.76001618, 0.9312527 , 0.71323907, 0.78996854,\n",
       "       0.85216701, 0.8670718 , 0.52224651, 0.83146788, 0.52900824,\n",
       "       0.82907961, 0.63735127, 0.7213755 , 0.60604144, 0.71254629,\n",
       "       0.69096818, 0.71203024, 0.48920396, 0.57788565, 0.62072763,\n",
       "       0.77071821, 0.63439042, 0.8144565 , 0.64618521, 0.74705573,\n",
       "       0.93301704, 0.91134354, 0.78390485, 0.74312612, 0.62319406,\n",
       "       0.84438783, 0.88619667, 0.69132913, 0.85125167, 0.7676874 ,\n",
       "       0.81208925, 0.6632246 , 0.86094383, 0.73774908, 0.93738594,\n",
       "       0.95505968, 0.66566527, 0.73740915, 0.72116982, 0.51237951,\n",
       "       0.87384749, 0.79914948, 0.75672945, 0.61805079, 0.7784145 ,\n",
       "       0.52690164, 0.76731965, 0.98648489, 0.55625635, 0.60242478,\n",
       "       0.83040941, 0.65906794, 0.47455509, 0.49607503, 0.7423763 ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlr.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97, 0.89, 0.8 , 0.96, 0.72, 0.94, 0.72, 0.46, 0.61, 0.63, 0.62,\n",
       "       0.44, 0.64, 0.65, 0.69, 0.55, 0.65, 0.64, 0.65, 0.54, 0.82, 0.84,\n",
       "       0.78, 0.76, 0.71, 0.47, 0.76, 0.94, 0.91, 0.82, 0.8 , 0.93, 0.89,\n",
       "       0.94, 0.69, 0.78, 0.92, 0.64, 0.84, 0.42, 0.6 , 0.51, 0.73, 0.75,\n",
       "       0.68, 0.77, 0.9 , 0.91, 0.85, 0.54, 0.86, 0.76, 0.61, 0.67, 0.71,\n",
       "       0.92, 0.92, 0.97, 0.96, 0.86, 0.71, 0.53, 0.96, 0.85, 0.42, 0.79,\n",
       "       0.56, 0.62, 0.96, 0.92, 0.93, 0.82, 0.68, 0.64, 0.88, 0.64, 0.84,\n",
       "       0.64, 0.82, 0.86, 0.67, 0.89, 0.74, 0.65, 0.72, 0.76, 0.73, 0.89,\n",
       "       0.87, 0.94, 0.95, 0.79, 0.89, 0.65, 0.78, 0.88, 0.91, 0.56, 0.81,\n",
       "       0.54, 0.83, 0.69, 0.72, 0.71, 0.56, 0.63, 0.66, 0.54, 0.57, 0.71,\n",
       "       0.69, 0.66, 0.79, 0.57, 0.75, 0.94, 0.91, 0.77, 0.73, 0.64, 0.92,\n",
       "       0.9 , 0.71, 0.88, 0.82, 0.8 , 0.66, 0.78, 0.71, 0.92, 0.92, 0.66,\n",
       "       0.76, 0.74, 0.49, 0.91, 0.81, 0.78, 0.59, 0.79, 0.36, 0.78, 0.96,\n",
       "       0.5 , 0.62, 0.85, 0.7 , 0.49, 0.45, 0.73])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8759152069448248"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95505968])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr.predict(sc.transform([[337,118,4.5,9.65,1]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
